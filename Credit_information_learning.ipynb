{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6LTgjMTEbPo2lpkEHxGBg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amarmurun0212/Diver/blob/main/Credit_information_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rP_YCfA8dxcV"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def missing_data(data):\n",
        "    total = data.isnull().sum().sort_values(ascending = False)\n",
        "    percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)\n",
        "    return pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "\n",
        "def Encoder(df):\n",
        "    columnsToEncode = list(df.select_dtypes(include=['category','object']))\n",
        "    le = LabelEncoder()\n",
        "    for feature in columnsToEncode:\n",
        "        try:\n",
        "            df[feature] = le.fit_transform(df[feature])\n",
        "        except:\n",
        "            print('Error encoding '+feature)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 1] Confirmation of the content of the competition"
      ],
      "metadata": {
        "id": "7neS5V_geMJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. what to learn and what to predict\n",
        "\n",
        "Many people struggle to get loans due to insufficient or non-existent credit histories. But writing an algorithm to accurately calculate that we are a reliable borrower by researching and predict on loan repayment.\n",
        "\n",
        "2. What kind of file to create and submit to Kaggle\n",
        "\n",
        "For each SK_ID_CURR in the test set, you must predict a probability for the TARGET variable. The file should contain a header and have the following format:\n",
        "\n",
        "  SK_ID_CURR,TARGET\n",
        "\n",
        "  100001,0.1\n",
        "\n",
        "  100005,0.9\n",
        "\n",
        "  100013,0.2\n",
        "\n",
        "  etc.\n",
        "\n",
        "3. What kind of index value will the submitted work be evaluated by?\n",
        "\n",
        "Probability"
      ],
      "metadata": {
        "id": "fiSVe2YVeM5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Problem 2] Learning and verification"
      ],
      "metadata": {
        "id": "ro4eWHdxeO4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app_train = pd.read_csv('application_train.csv')\n",
        "app_test = pd.read_csv('application_test.csv')\n",
        "\n",
        "print(\"Number of samples {} and feature {} in application_train.\".format(len(app_train),len(app_train.columns)))\n",
        "print(\"Number of samples {} and feature {} in application_test.\".format(len(app_test),len(app_test.columns)))\n",
        "print(app_test.columns)\n",
        "\n",
        "app_train.dropna(axis = 1, how='any', inplace=True)\n",
        "y_train = app_train['TARGET']\n",
        "app_train = app_train.drop(\"TARGET\", axis=1)\n",
        "\n",
        "app_test = app_test[app_train.columns]\n",
        "print(app_train.head(10))\n",
        "\n",
        "app_train = Encoder(app_train)\n",
        "app_test = Encoder(app_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(app_train)\n",
        "X_train = scaler.transform(app_train)\n",
        "X_test = scaler.transform(app_test)\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(X_train, y_train, random_state=123)\n",
        "\n",
        "lr = LogisticRegression(C=0.0001)\n",
        "lr.fit(x_tr, y_tr)\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SKoUP3TsXm_1",
        "outputId": "17ded1e2-ed94-45c2-d38a-dda9be5d762a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples 307511 and feature 122 in application_train.\n",
            "Number of samples 48744 and feature 121 in application_test.\n",
            "Index(['SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR',\n",
            "       'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT',\n",
            "       'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
            "       ...\n",
            "       'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20',\n",
            "       'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
            "       'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
            "       'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
            "       'AMT_REQ_CREDIT_BUREAU_YEAR'],\n",
            "      dtype='object', length=121)\n",
            "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
            "0      100002         Cash loans           M            N               Y   \n",
            "1      100003         Cash loans           F            N               N   \n",
            "2      100004    Revolving loans           M            Y               Y   \n",
            "3      100006         Cash loans           F            N               Y   \n",
            "4      100007         Cash loans           M            N               Y   \n",
            "5      100008         Cash loans           M            N               Y   \n",
            "6      100009         Cash loans           F            Y               Y   \n",
            "7      100010         Cash loans           M            Y               Y   \n",
            "8      100011         Cash loans           F            N               Y   \n",
            "9      100012    Revolving loans           M            N               Y   \n",
            "\n",
            "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT      NAME_INCOME_TYPE  \\\n",
            "0             0          202500.0    406597.5               Working   \n",
            "1             0          270000.0   1293502.5         State servant   \n",
            "2             0           67500.0    135000.0               Working   \n",
            "3             0          135000.0    312682.5               Working   \n",
            "4             0          121500.0    513000.0               Working   \n",
            "5             0           99000.0    490495.5         State servant   \n",
            "6             1          171000.0   1560726.0  Commercial associate   \n",
            "7             0          360000.0   1530000.0         State servant   \n",
            "8             0          112500.0   1019610.0             Pensioner   \n",
            "9             0          135000.0    405000.0               Working   \n",
            "\n",
            "             NAME_EDUCATION_TYPE  ... FLAG_DOCUMENT_12 FLAG_DOCUMENT_13  \\\n",
            "0  Secondary / secondary special  ...                0                0   \n",
            "1               Higher education  ...                0                0   \n",
            "2  Secondary / secondary special  ...                0                0   \n",
            "3  Secondary / secondary special  ...                0                0   \n",
            "4  Secondary / secondary special  ...                0                0   \n",
            "5  Secondary / secondary special  ...                0                0   \n",
            "6               Higher education  ...                0                0   \n",
            "7               Higher education  ...                0                0   \n",
            "8  Secondary / secondary special  ...                0                0   \n",
            "9  Secondary / secondary special  ...                0                0   \n",
            "\n",
            "   FLAG_DOCUMENT_14  FLAG_DOCUMENT_15  FLAG_DOCUMENT_16  FLAG_DOCUMENT_17  \\\n",
            "0                 0                 0                 0                 0   \n",
            "1                 0                 0                 0                 0   \n",
            "2                 0                 0                 0                 0   \n",
            "3                 0                 0                 0                 0   \n",
            "4                 0                 0                 0                 0   \n",
            "5                 0                 0                 0                 0   \n",
            "6                 1                 0                 0                 0   \n",
            "7                 0                 0                 0                 0   \n",
            "8                 0                 0                 0                 0   \n",
            "9                 0                 0                 0                 0   \n",
            "\n",
            "   FLAG_DOCUMENT_18  FLAG_DOCUMENT_19  FLAG_DOCUMENT_20  FLAG_DOCUMENT_21  \n",
            "0                 0                 0                 0                 0  \n",
            "1                 0                 0                 0                 0  \n",
            "2                 0                 0                 0                 0  \n",
            "3                 0                 0                 0                 0  \n",
            "4                 0                 0                 0                 0  \n",
            "5                 0                 0                 0                 0  \n",
            "6                 0                 0                 0                 0  \n",
            "7                 0                 0                 0                 0  \n",
            "8                 0                 0                 0                 0  \n",
            "9                 0                 0                 0                 0  \n",
            "\n",
            "[10 rows x 54 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=0.0001)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.0001)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3: Estimation for test data."
      ],
      "metadata": {
        "id": "d-pElLAwdJdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = lr.predict_proba(x_val)[:, 1]\n",
        "print(\"roc auc score\", roc_auc_score(y_val, y_test_pred))\n",
        "\n",
        "y_test_pred = lr.predict_proba(X_test)[:, 1]\n",
        "data = app_test[[\"SK_ID_CURR\"]]\n",
        "data['TARGET'] = y_test_pred.tolist()\n",
        "data.to_csv('submission.csv', index=False)\n",
        "print(data)\n",
        "\n",
        "print(\"BEST SCORE: 0.64511  V2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcBWOKu1dMl9",
        "outputId": "66ae9042-4a3e-48cb-d1d9-9a8b7d393e55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roc auc score 0.6520682025451561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-602a985e68c2>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['TARGET'] = y_test_pred.tolist()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       SK_ID_CURR    TARGET\n",
            "0          100001  0.061083\n",
            "1          100005  0.101110\n",
            "2          100013  0.051799\n",
            "3          100028  0.074639\n",
            "4          100038  0.116959\n",
            "...           ...       ...\n",
            "48739      456221  0.084149\n",
            "48740      456222  0.095559\n",
            "48741      456223  0.070960\n",
            "48742      456224  0.101302\n",
            "48743      456250  0.083266\n",
            "\n",
            "[48744 rows x 2 columns]\n",
            "BEST SCORE: 0.64511  V2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "mW4jVAKpdQmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4: Feature Engineering."
      ],
      "metadata": {
        "id": "UKS1AGOjdTK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "application_train = pd.read_csv('application_train.csv')\n",
        "application_test = pd.read_csv('application_test.csv')\n",
        "\n",
        "correlations = application_train.corr()[\"TARGET\"].sort_values()\n",
        "\n",
        "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
        "print('\\nMost Negative Correlations:\\n', correlations.head(15))\n",
        "\n",
        "print('\\nFrom above result, We can see that the most correlated variables are \\\n",
        "DAYS_BIRTH, EXT_SOURCE_3, EXT_SOURCE_2 and EXT_SOURCE_1.\\n')     \n",
        "\n",
        "\n",
        "ext_data = application_train[['TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
        "ext_data_corrs = ext_data.corr()\n",
        "print(ext_data_corrs)\n",
        "\n",
        "\n",
        "y_ext = ext_data['TARGET']\n",
        "X_train = ext_data.drop(columns=['TARGET'])\n",
        "X_test = application_test[X_train.columns]\n",
        "\n",
        "print(X_train.columns)\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.fit_transform(X_test)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "train = scaler.transform(X_train)\n",
        "test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(train, y_ext, random_state=123)\n",
        "\n",
        "log_reg = LogisticRegression(C=0.0001)\n",
        "log_reg.fit(x_tr, y_tr)\n",
        "\n",
        "log_reg_pred = log_reg.predict_proba(x_val)[:, 1]\n",
        "print(\"roc auc score\", roc_auc_score(y_val, log_reg_pred))\n",
        "\n",
        "y_test_pred = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "data = application_test[[\"SK_ID_CURR\"]]\n",
        "data['TARGET'] = y_test_pred.tolist()\n",
        "data.to_csv('submission.csv', index=False)\n",
        "print(data)\n",
        "\n",
        "print(\"BEST SCORE: 0.69758  V3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks-r23gldUys",
        "outputId": "3fa3db5d-b75a-499e-a4f5-149c0b148f37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-44bbb2d13c28>:4: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  correlations = application_train.corr()[\"TARGET\"].sort_values()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Positive Correlations:\n",
            " DEF_60_CNT_SOCIAL_CIRCLE       0.031276\n",
            "DEF_30_CNT_SOCIAL_CIRCLE       0.032248\n",
            "LIVE_CITY_NOT_WORK_CITY        0.032518\n",
            "OWN_CAR_AGE                    0.037612\n",
            "DAYS_REGISTRATION              0.041975\n",
            "FLAG_DOCUMENT_3                0.044346\n",
            "REG_CITY_NOT_LIVE_CITY         0.044395\n",
            "FLAG_EMP_PHONE                 0.045982\n",
            "REG_CITY_NOT_WORK_CITY         0.050994\n",
            "DAYS_ID_PUBLISH                0.051457\n",
            "DAYS_LAST_PHONE_CHANGE         0.055218\n",
            "REGION_RATING_CLIENT           0.058899\n",
            "REGION_RATING_CLIENT_W_CITY    0.060893\n",
            "DAYS_BIRTH                     0.078239\n",
            "TARGET                         1.000000\n",
            "Name: TARGET, dtype: float64\n",
            "\n",
            "Most Negative Correlations:\n",
            " EXT_SOURCE_3                 -0.178919\n",
            "EXT_SOURCE_2                 -0.160472\n",
            "EXT_SOURCE_1                 -0.155317\n",
            "DAYS_EMPLOYED                -0.044932\n",
            "FLOORSMAX_AVG                -0.044003\n",
            "FLOORSMAX_MEDI               -0.043768\n",
            "FLOORSMAX_MODE               -0.043226\n",
            "AMT_GOODS_PRICE              -0.039645\n",
            "REGION_POPULATION_RELATIVE   -0.037227\n",
            "ELEVATORS_AVG                -0.034199\n",
            "ELEVATORS_MEDI               -0.033863\n",
            "FLOORSMIN_AVG                -0.033614\n",
            "FLOORSMIN_MEDI               -0.033394\n",
            "LIVINGAREA_AVG               -0.032997\n",
            "LIVINGAREA_MEDI              -0.032739\n",
            "Name: TARGET, dtype: float64\n",
            "\n",
            "From above result, We can see that the most correlated variables are DAYS_BIRTH, EXT_SOURCE_3, EXT_SOURCE_2 and EXT_SOURCE_1.\n",
            "\n",
            "                TARGET  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  DAYS_BIRTH\n",
            "TARGET        1.000000     -0.155317     -0.160472     -0.178919    0.078239\n",
            "EXT_SOURCE_1 -0.155317      1.000000      0.213982      0.186846   -0.600610\n",
            "EXT_SOURCE_2 -0.160472      0.213982      1.000000      0.109167   -0.091996\n",
            "EXT_SOURCE_3 -0.178919      0.186846      0.109167      1.000000   -0.205478\n",
            "DAYS_BIRTH    0.078239     -0.600610     -0.091996     -0.205478    1.000000\n",
            "Index(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'], dtype='object')\n",
            "roc auc score 0.71809206308055\n",
            "       SK_ID_CURR  TARGET\n",
            "0          100001     0.0\n",
            "1          100005     0.0\n",
            "2          100013     0.0\n",
            "3          100028     0.0\n",
            "4          100038     0.0\n",
            "...           ...     ...\n",
            "48739      456221     0.0\n",
            "48740      456222     0.0\n",
            "48741      456223     0.0\n",
            "48742      456224     0.0\n",
            "48743      456250     0.0\n",
            "\n",
            "[48744 rows x 2 columns]\n",
            "BEST SCORE: 0.69758  V3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-44bbb2d13c28>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['TARGET'] = y_test_pred.tolist()\n"
          ]
        }
      ]
    }
  ]
}